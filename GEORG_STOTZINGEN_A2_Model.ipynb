{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Georg\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8005\n",
      "Testing  ACCURACY: 0.8111\n",
      "AUC Score        : 0.8187\n",
      "Training ACCURACY: 0.8005\n",
      "Testing  ACCURACY: 0.8111\n",
      "AUC Score        : 0.8187\n",
      "Training ACCURACY: 0.8005\n",
      "Testing  ACCURACY: 0.8111\n",
      "AUC Score        : 0.8187\n",
      "12.324253200000001\n"
     ]
    }
   ],
   "source": [
    "# timeit\n",
    "# importing timeit\n",
    "import timeit\n",
    "code_to_test =  \"\"\"\n",
    "# Student Name : Georg Stotzingen\n",
    "# Cohort       : 1 Lombard\n",
    "\n",
    "# Note: You are only allowed to submit ONE final model for this assignment.\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Import Packages\n",
    "################################################################################\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random as rand\n",
    "import statsmodels.formula.api as smf\n",
    "import sklearn.linear_model\n",
    "import pydotplus\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz       \n",
    "from sklearn.externals.six import StringIO     \n",
    "from IPython.display import Image              \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Load Data\n",
    "################################################################################\n",
    "\n",
    "# use this space to load the original dataset\n",
    "# MAKE SURE TO SAVE THE ORIGINAL FILE AS original_df\n",
    "# Example: original_df = pd.read_excel('Apprentice Chef Dataset.xlsx')\n",
    "\n",
    "original_df = pd.read_excel('C:/Users/Georg/Desktop/Hult/MSBA/Machine Learning/Case/Apprentice_Chef_Dataset.xlsx')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Feature Engineering and (optional) Dataset Standardization\n",
    "################################################################################\n",
    "\n",
    "# use this space for all of the feature engineering that is required for your\n",
    "# final model\n",
    "\n",
    "# if your final model requires dataset standardization, do this here as well\n",
    "\n",
    "# making a copy and shorter name to protect original_df\n",
    "\n",
    "df=original_df.copy()\n",
    "\n",
    "# lower casing for easier working\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "# adjusting display options and setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "# calculating if they bought any beverages.\n",
    "\n",
    "# from the case description, max price per meal is $23\n",
    "# so every order above must include drinks\n",
    "# max non alcoholic drink price is $5\n",
    "# so every order above $28 must include wine\n",
    "# also, we will try to factor in reductions for weekly plans\n",
    "# added safeguard for new customers without revenue\n",
    "\n",
    "df['avg_spend'] = df['revenue']/df['total_meals_ordered']\n",
    "avg_spend_change_hi = 23\n",
    "df['beverages'] = 0\n",
    "condition = df.loc[0:,'beverages'][df['avg_spend'] > avg_spend_change_hi]\n",
    "condition_0 = df.loc[0:,'beverages'][df['avg_spend'] == 0]\n",
    "\n",
    "df['beverages'].replace(to_replace = condition,\n",
    "                                      value      = 1,\n",
    "                                      inplace    = True)\n",
    "df['beverages'].replace(to_replace = condition_0,\n",
    "                                      value      = 0,\n",
    "                                      inplace    = True)\n",
    "\n",
    "avg_spend_change_alc = 28\n",
    "df['alcohol'] = 0\n",
    "condition = df.loc[0:,'alcohol'][df['avg_spend'] > avg_spend_change_alc]\n",
    "condition_0 = df.loc[0:,'alcohol'][df['avg_spend'] == 0]\n",
    "\n",
    "df['alcohol'].replace(to_replace = condition,\n",
    "                                      value      = 1,\n",
    "                                      inplace    = True)\n",
    "df['alcohol'].replace(to_replace = condition_0,\n",
    "                                      value      = 0,\n",
    "                                      inplace    = True)\n",
    "\n",
    "# maximum average spend should be $23+25=48\n",
    "# but some averages are much higher. Investigate further\n",
    "# total meals ordered seems to be really number of total orders\n",
    "\n",
    "# adding complaints as a percentage of total meals ordered\n",
    "df['perc_complaints'] = df['contacts_w_customer_service']/df['total_meals_ordered']\n",
    "\n",
    "# adding tendency to try new meals\n",
    "df['new_meal_tendency'] = df['unique_meals_purch']/df['total_meals_ordered']\n",
    "\n",
    "# adding perc of meals ordered as part of a meal plan, assuming an average 4 meals per plan\n",
    "df['perc_meal_plan'] = df['weekly_plan']*4/df['total_meals_ordered']\n",
    "\n",
    "# adding cancelations percentage of total orders\n",
    "# busy customers could have different cross sell habits\n",
    "df['perc_cancelations_before_noon'] = df['cancellations_before_noon']/df['total_meals_ordered']\n",
    "df['perc_cancelations_after_noon'] = df['cancellations_after_noon']/df['total_meals_ordered']\n",
    "\n",
    "#adding total_meals_ordered *followed_recommendations_pct/100\n",
    "#shows how many orders where completed as recommendations\n",
    "df['recommended_meals'] = df['total_meals_ordered']*df['followed_recommendations_pct']/100\n",
    "\n",
    "# adding clicks_per_time\n",
    "# this could estimate the activity while being on the website\n",
    "df['clicks_per_time'] = df['avg_clicks_per_visit']/df['avg_time_per_site_visit']\n",
    "\n",
    "#adding contacts_w_customer_service - early_deliveries -late_deliveries\n",
    "#complaints would often be about the timing of the food\n",
    "#complaints when the food was on time suggests other issues\n",
    "df['on_time_complaints'] = df['contacts_w_customer_service']-df['early_deliveries']-df['late_deliveries']\n",
    "\n",
    "# adding unique_meals_purch/product_categories_viewed\n",
    "# this could be a proxy for curiosity\n",
    "df['cat_viewed_purchased'] = df['unique_meals_purch']/df['product_categories_viewed']\n",
    "\n",
    "# adding avg_time_per_site_visit/product_categories_viewed\n",
    "# could show how quickly people decide\n",
    "df['time_per_category'] = df['avg_time_per_site_visit']/df['product_categories_viewed']\n",
    "\n",
    "#adding revenue/avg_time_per_site_visit\n",
    "df['revenue_per_time'] = df['revenue']/df['avg_time_per_site_visit']\n",
    "\n",
    "#adding revenue/avg_clicks_per_visit\n",
    "df['revenue_per_click'] = df['revenue']/df['avg_clicks_per_visit']\n",
    "\n",
    "#adding total cancelations\n",
    "df['total_cancelations'] = df['cancellations_after_noon']+df['cancellations_before_noon']\n",
    "\n",
    "#adding total_photos_viewed/avg_time_per_site_visit\n",
    "df['photos_per_time'] = df['total_photos_viewed']/df['avg_time_per_site_visit']\n",
    "\n",
    "#adding avg_time_per_site_visit + avg_prep_vid_time\n",
    "#could proxy engagement \n",
    "df['total_time'] = df['avg_time_per_site_visit']+df['avg_prep_vid_time']\n",
    "\n",
    "#adding largest_order_size*total_meals_ordered\n",
    "#since we are not sure if total_meals_ordered is meals or orders, this is the maximum meals ordered\n",
    "df['max_potential_meals'] = df['largest_order_size']*df['total_meals_ordered']\n",
    "\n",
    "#adding total_meals_ordered/largest_order_size\n",
    "#if it is number of meals, this is the minimum amount of orders\n",
    "df['min_potential_orders'] = df['total_meals_ordered']/df['largest_order_size']\n",
    "\n",
    "#adding revenue + avg_spend*cancellations_before_noon + avg_spend*cancellations_after_noon*0.5\n",
    "#adjusting revenue for cancelations\n",
    "df['adjusted_revenue'] = df['revenue']+df['avg_spend']*df['cancellations_before_noon']+ df['avg_spend']*df['cancellations_after_noon']*0.5\n",
    "\n",
    "#adding mobile_logins + pc_logins\n",
    "df['total_logins'] = df['mobile_logins']+df['pc_logins']\n",
    "\n",
    "#adding followed_recommendations_pct*median_meal_rating\n",
    "#could proxy satisfaction with recommendations\n",
    "df['recommendations_satisfaction'] = df['followed_recommendations_pct']*df['median_meal_rating']\n",
    "\n",
    "#adding followed_recommendations_pct/contacts_w_customer_service\n",
    "df['complaints_on_recommendations'] = df['followed_recommendations_pct']/df['contacts_w_customer_service']\n",
    "\n",
    "# creating columns for email categorization\n",
    "\n",
    "# Splitting emails to categorise them\n",
    "\n",
    "# STEP 1: splitting personal emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in df.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = df.loc[index, 'email'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# STEP 2: concatenating with original DataFrame\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['0' , 'email_domain']\n",
    "\n",
    "\n",
    "# concatenating email_domain with df DataFrame\n",
    "df = pd.concat([df, email_df['email_domain']],\n",
    "                     axis = 1)\n",
    "\n",
    "# aggreate emails\n",
    "\n",
    "# email domain types\n",
    "personal_email_domains = [  '@gmail.com',\n",
    "                            '@yahoo.com',\n",
    "                            '@protonmail.com']\n",
    "professional_email_domains = ['@mmm.com',\n",
    "                            '@amex.com',\n",
    "                            '@apple.com',\n",
    "                            '@boeing.com',\n",
    "                            '@caterpillar.com',\n",
    "                            '@chevron.com',\n",
    "                            '@cisco.com',\n",
    "                            '@cocacola.com',\n",
    "                            '@disney.com',\n",
    "                            '@dupont.com',\n",
    "                            '@exxon.com',\n",
    "                            '@ge.org',\n",
    "                            '@goldmansacs.com',\n",
    "                            '@homedepot.com',\n",
    "                            '@ibm.com',\n",
    "                            '@intel.com',\n",
    "                            '@jnj.com',\n",
    "                            '@jpmorgan.com',\n",
    "                            '@mcdonalds.com',\n",
    "                            '@merck.com',\n",
    "                            '@microsoft.com',\n",
    "                            '@nike.com',\n",
    "                            '@pfizer.com',\n",
    "                            '@pg.com',\n",
    "                            '@travelers.com',\n",
    "                            '@unitedtech.com',\n",
    "                            '@unitedhealth.com',\n",
    "                            '@verizon.com',\n",
    "                            '@visa.com',\n",
    "                            '@walmart.com']\n",
    "\n",
    "junk_email_domains  = [     '@me.com',\n",
    "                            '@aol.com',\n",
    "                            '@hotmail.com',\n",
    "                            '@live.com',\n",
    "                            '@msn.com',\n",
    "                            '@passport.com']\n",
    "\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in df['email_domain']:\n",
    "    \n",
    "    if '@' + domain in personal_email_domains:\n",
    "        placeholder_lst.append('personal')\n",
    "        \n",
    "\n",
    "    elif '@' + domain in professional_email_domains:\n",
    "        placeholder_lst.append('professional')\n",
    "        \n",
    "        \n",
    "    elif '@' + domain in junk_email_domains:\n",
    "        placeholder_lst.append('junk')\n",
    "\n",
    "\n",
    "    else:\n",
    "            print('Unknown')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "df['domain_group'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# creating dummy variables for email domain groups\n",
    "one_hot_domain_group = pd.get_dummies(df['domain_group'])\n",
    "\n",
    "# joining codings together\n",
    "df = df.join([one_hot_domain_group])\n",
    "\n",
    "# adding column for where first and last names are the same\n",
    "\n",
    "df['dif_names'] = 0\n",
    "condition = df.loc[0:,'first_name'] == df.loc[0:,'family_name']\n",
    "\n",
    "df['dif_names'].replace(to_replace = condition,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "df['same_names'] = 0\n",
    "names_placeholder_lst=[]\n",
    "for i in df['dif_names']:\n",
    "    \n",
    "    if i == 0:\n",
    "        names_placeholder_lst.append(1)\n",
    "    else:\n",
    "        names_placeholder_lst.append(0)\n",
    "        \n",
    "df['same_names'] = pd.Series(names_placeholder_lst)\n",
    "        \n",
    "# print(df['same_names'].value_counts())\n",
    "\n",
    "#creating a dummy for families of at least four members\n",
    "\n",
    "family_list= ['Frey',\n",
    "'Targaryen',\n",
    "'Stark',\n",
    "'Tyrell',\n",
    "'Lannister',\n",
    "'Hightower',\n",
    "'Greyjoy',\n",
    "'Florent',\n",
    "'Vance',\n",
    "'Botley',\n",
    "'Royce',\n",
    "'Rivers',\n",
    "'Martell',\n",
    "'Crakehall',\n",
    "'Harlaw',\n",
    "'Arryn',\n",
    "'Baratheon',\n",
    "'Bracken',\n",
    "'Sand',\n",
    "'Waynwood',\n",
    "'Velaryon',\n",
    "'Seaworth',\n",
    "'Westerling',\n",
    "'Flowers',\n",
    "'Plumm',\n",
    "'Redwyne',\n",
    "'Karstark',\n",
    "'Fossoway',\n",
    "'Osgrey',\n",
    "'Brax',\n",
    "'Mormont',\n",
    "'Swann',\n",
    "'I Targaryen',\n",
    "'Wylde',\n",
    "'Paege',\n",
    "'Drumm',\n",
    "'Goodbrother',\n",
    "'Tallhart',\n",
    "'zo Loraq',\n",
    "'Beesbury',\n",
    "'Mallister',\n",
    "'Manderly',\n",
    "'Glover',\n",
    "'Umber',\n",
    "'Estermont',\n",
    "'Swyft',\n",
    "'Dayne',\n",
    "'Darry',\n",
    "'Caswell',\n",
    "'Farwynd',\n",
    "'Norcross',\n",
    "'Redfort',\n",
    "'Blackwood',\n",
    "'Heddle',\n",
    "'Flint',\n",
    "'II Targaryen',\n",
    "'Hollard',\n",
    "'Crane',\n",
    "'Whent',\n",
    "'Ryswell',\n",
    "'Oakheart',\n",
    "'Tully',\n",
    "'Haigh',\n",
    "'Crabb',\n",
    "'Hornwood',\n",
    "'Ambrose',\n",
    "'Smallwood',\n",
    "'Pyke',\n",
    "'Connington',\n",
    "'Ironmaker',\n",
    "'Cassel',\n",
    "'Lothston',\n",
    "'Tarly',\n",
    "'Hunter',\n",
    "'Strong',\n",
    "'Kettleblack',\n",
    "'Slynt',\n",
    "'Hill',\n",
    "'Stokeworth',\n",
    "'Storm',\n",
    "'Caron',\n",
    "'Yronwood',\n",
    "'Farring',\n",
    "'Manwoody',\n",
    "'Goodbrook',\n",
    "'III Targaryen', # manual cleanup of impurities in the dataset\n",
    "'IV Targaryen',  # manual cleanup of impurities in the dataset\n",
    "'V Targaryen',   # manual cleanup of impurities in the dataset\n",
    "'Corbray']\n",
    "\n",
    "df['family'] = 0\n",
    "family_placeholder_lst=[]\n",
    "for name in df['family_name']:\n",
    "    \n",
    "    if name in family_list:\n",
    "        family_placeholder_lst.append(1)\n",
    "    else:\n",
    "        family_placeholder_lst.append(0)\n",
    "        \n",
    "df['family'] = pd.Series(family_placeholder_lst)\n",
    "        \n",
    "#print(df['family'].value_counts())\n",
    "\n",
    "#creating a dummy for unique family names\n",
    "family1_list=['Frey',\n",
    "'Targaryen',\n",
    "'Stark',\n",
    "'Tyrell',\n",
    "'Lannister',\n",
    "'Hightower',\n",
    "'Greyjoy',\n",
    "'Florent',\n",
    "'Vance',\n",
    "'Botley',\n",
    "'Royce',\n",
    "'Rivers',\n",
    "'Martell',\n",
    "'Crakehall',\n",
    "'Harlaw',\n",
    "'Arryn',\n",
    "'Baratheon',\n",
    "'Bracken',\n",
    "'Sand',\n",
    "'Waynwood',\n",
    "'Velaryon',\n",
    "'Seaworth',\n",
    "'Westerling',\n",
    "'Flowers',\n",
    "'Plumm',\n",
    "'Redwyne',\n",
    "'Karstark',\n",
    "'Fossoway',\n",
    "'Osgrey',\n",
    "'Brax',\n",
    "'Mormont',\n",
    "'Swann',\n",
    "'I Targaryen',\n",
    "'Wylde',\n",
    "'Paege',\n",
    "'Drumm',\n",
    "'Goodbrother',\n",
    "'Tallhart',\n",
    "'zo Loraq',\n",
    "'Beesbury',\n",
    "'Mallister',\n",
    "'Manderly',\n",
    "'Glover',\n",
    "'Umber',\n",
    "'Estermont',\n",
    "'Swyft',\n",
    "'Dayne',\n",
    "'Darry',\n",
    "'Caswell',\n",
    "'Farwynd',\n",
    "'Norcross',\n",
    "'Redfort',\n",
    "'Blackwood',\n",
    "'Heddle',\n",
    "'Flint',\n",
    "'II Targaryen',\n",
    "'Hollard',\n",
    "'Crane',\n",
    "'Whent',\n",
    "'Ryswell',\n",
    "'Oakheart',\n",
    "'Tully',\n",
    "'Haigh',\n",
    "'Crabb',\n",
    "'Hornwood',\n",
    "'Ambrose',\n",
    "'Smallwood',\n",
    "'Pyke',\n",
    "'Connington',\n",
    "'Ironmaker',\n",
    "'Cassel',\n",
    "'Lothston',\n",
    "'Tarly',\n",
    "'Hunter',\n",
    "'Strong',\n",
    "'Kettleblack',\n",
    "'Slynt',\n",
    "'Hill',\n",
    "'Stokeworth',\n",
    "'Storm',\n",
    "'Caron',\n",
    "'Yronwood',\n",
    "'Farring',\n",
    "'Manwoody',\n",
    "'Goodbrook',\n",
    "'Corbray',\n",
    "'Stackspear',\n",
    "'Bulwer',\n",
    "'Spicer',\n",
    "'Penrose',\n",
    "'Waters',\n",
    "'Lefford',\n",
    "'Staunton',\n",
    "'Vypren',\n",
    "'Stone',\n",
    "'Hoare',\n",
    "'Payne',\n",
    "'Kenning',\n",
    "'Penny',\n",
    "'Piper',\n",
    "'Uller',\n",
    "'Stout',\n",
    "'Darklyn',\n",
    "'Qorgyle',\n",
    "'Terys',\n",
    "'Brune',\n",
    "'Costayne',\n",
    "'Locke',\n",
    "'Bolton',\n",
    "'Mooton',\n",
    "'Santagar',\n",
    "'Rowan',\n",
    "'Morrigen',\n",
    "'Ashford',\n",
    "'of Oldtown',\n",
    "'Grafton',\n",
    "'Reed',\n",
    "'Marbrand',\n",
    "'Hardyng',\n",
    "'Sharp',\n",
    "'Blackmont',\n",
    "'Webber',\n",
    "'Willum',\n",
    "'Snow',\n",
    "'Alyn',\n",
    "'Toyne',\n",
    "'Meadows',\n",
    "'Dalt',\n",
    "'Jordayne',\n",
    "'Rosby',\n",
    "'Poole',\n",
    "'Cuy',\n",
    "'Uffering',\n",
    "'Boy',\n",
    "'of Pennytree',\n",
    "'Wells',\n",
    "'Hewett',\n",
    "'Mullendore',\n",
    "'Rykker',\n",
    "'Selmy',\n",
    "'Henly',\n",
    "'Greenfield',\n",
    "'Prestayn',\n",
    "'Hetherspoon',\n",
    "'Dothare',\n",
    "'zo Galare',\n",
    "'Dustin',\n",
    "'Tarth',\n",
    "'Mo',\n",
    "'Ryger',\n",
    "'Thorne',\n",
    "'Inchfield',\n",
    "'Hunt',\n",
    "'Prester',\n",
    "'Dondarrion',\n",
    "'Humble',\n",
    "'Allyrion',\n",
    "'Tollett',\n",
    "'Dick',\n",
    "'Jeyne',\n",
    "'Lonmouth',\n",
    "'Serry',\n",
    "'Rolfe',\n",
    "'Lydden',\n",
    "'Bernarr',\n",
    "'Clifton',\n",
    "'Lorch',\n",
    "'Clegane',\n",
    "'Blacktyde',\n",
    "'Shepherd',\n",
    "'Fell',\n",
    "'Lynderly',\n",
    "'Vaith',\n",
    "'Norrey',\n",
    "'Cerwyn',\n",
    "'Nayland',\n",
    "'Blackfyre',\n",
    "'Charlton',\n",
    "'Otherys',\n",
    "'Wythers',\n",
    "'Blackberry',\n",
    "'Codd',\n",
    "'Peake',\n",
    "'Belmore',\n",
    "'Ben',\n",
    "'Woodwright',\n",
    "'Wull',\n",
    "'Knight',\n",
    "'Wynch',\n",
    "'King']\n",
    "\n",
    "df['unique_name'] = 0\n",
    "family1_placeholder_lst=[]\n",
    "for name in df['family_name']:\n",
    "    \n",
    "    if name in family1_list:\n",
    "        family1_placeholder_lst.append(0)\n",
    "    else:\n",
    "        family1_placeholder_lst.append(1)\n",
    "        \n",
    "df['unique_name'] = pd.Series(family1_placeholder_lst)\n",
    "        \n",
    "#print(df['unique_name'].value_counts())\n",
    "\n",
    "#creating a dummy for family names that appear exactly twice\n",
    "# this will help to spot a potential trend change from 1 to 2\n",
    "\n",
    "family2_list=[\n",
    "'Alyn',\n",
    "'Toyne',\n",
    "'Meadows',\n",
    "'Dalt',\n",
    "'Jordayne',\n",
    "'Rosby',\n",
    "'Poole',\n",
    "'Cuy',\n",
    "'Uffering',\n",
    "'Boy',\n",
    "'of Pennytree',\n",
    "'Wells',\n",
    "'Hewett',\n",
    "'Mullendore',\n",
    "'Rykker',\n",
    "'Selmy',\n",
    "'Henly',\n",
    "'Greenfield',\n",
    "'Prestayn',\n",
    "'Hetherspoon',\n",
    "'Dothare',\n",
    "'zo Galare',\n",
    "'Dustin',\n",
    "'Tarth',\n",
    "'Mo',\n",
    "'Ryger',\n",
    "'Thorne',\n",
    "'Inchfield',\n",
    "'Hunt',\n",
    "'Prester',\n",
    "'Dondarrion',\n",
    "'Humble',\n",
    "'Allyrion',\n",
    "'Tollett',\n",
    "'Dick',\n",
    "'Jeyne',\n",
    "'Lonmouth',\n",
    "'Serry',\n",
    "'Rolfe',\n",
    "'Lydden',\n",
    "'Bernarr',\n",
    "'Clifton',\n",
    "'Lorch',\n",
    "'Clegane',\n",
    "'Blacktyde',\n",
    "'Shepherd',\n",
    "'Fell',\n",
    "'Lynderly',\n",
    "'Vaith',\n",
    "'Norrey',\n",
    "'Cerwyn',\n",
    "'Nayland',\n",
    "'Blackfyre',\n",
    "'Charlton',\n",
    "'Otherys',\n",
    "'Wythers',\n",
    "'Blackberry',\n",
    "'Codd',\n",
    "'Peake',\n",
    "'Belmore',\n",
    "'Ben',\n",
    "'Woodwright',\n",
    "'Wull',\n",
    "'Knight',\n",
    "'Wynch',\n",
    "'King']\n",
    "\n",
    "df['name_twice'] = 0\n",
    "family2_placeholder_lst=[]\n",
    "for name in df['family_name']:\n",
    "    \n",
    "    if name in family2_list:\n",
    "        family2_placeholder_lst.append(1)\n",
    "    else:\n",
    "        family2_placeholder_lst.append(0)\n",
    "        \n",
    "df['name_twice'] = pd.Series(family2_placeholder_lst)\n",
    "        \n",
    "#print(df['name_twice'].value_counts())\n",
    "\n",
    "#setting outlier thresholds\n",
    "\n",
    "revenue_hi                          = 5500\n",
    "revenue_lo                          = 1285 #from looking at quantiles\n",
    "total_meals_ordered_hi              = 220\n",
    "total_meals_ordered_lo              = 16\n",
    "unique_meals_purch_hi               = 8\n",
    "contacts_w_customer_service_hi      = 11\n",
    "contacts_w_customer_service_lo      = 3\n",
    "product_categories_viewed_hi        = 10\n",
    "product_categories_viewed_lo        = 2\n",
    "avg_time_per_site_visit_hi          = 240\n",
    "avg_time_per_site_visit_lo          = 20\n",
    "cancellations_before_noon_hi        = 5\n",
    "cancellations_after_noon_hi         = 1.5\n",
    "mobile_logins_lo                    = 5\n",
    "pc_logins_hi                        = 2\n",
    "pc_logins_lo                        = 1\n",
    "weekly_plan_hi                      = 20\n",
    "early_deliveries_hi                 = 5\n",
    "late_deliveries_hi                  = 7\n",
    "avg_prep_vid_time_hi                = 250\n",
    "largest_order_size_lo               = 2\n",
    "largest_order_size_hi               = 7\n",
    "master_classes_attended_hi          = 1\n",
    "median_meal_rating_hi               = 3\n",
    "median_meal_rating_lo               = 3\n",
    "avg_clicks_per_visit_lo             = 8\n",
    "avg_clicks_per_visit_hi             = 17\n",
    "total_photos_viewed_hi              = 350\n",
    "avg_spend_hi                        = 80\n",
    "perc_complaints_hi                  = 0.27\n",
    "new_meal_tendency_hi                = 0.3\n",
    "perc_meal_plan_hi                   = 3\n",
    "\n",
    "# Developing feature columns for outliers\n",
    "\n",
    "# total_meals_ordered_hi_lo\n",
    "df['out_total_meals_ordered'] = 0\n",
    "condition_hi = df.loc[0:,'out_total_meals_ordered'][df['total_meals_ordered'] > total_meals_ordered_hi]\n",
    "condition_lo = df.loc[0:,'out_total_meals_ordered'][df['total_meals_ordered'] < total_meals_ordered_lo]\n",
    "\n",
    "df['out_total_meals_ordered'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "df['out_total_meals_ordered'].replace(to_replace = condition_lo,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# unique_meals_purch_hi\n",
    "df['out_unique_meals_purch'] = 0\n",
    "condition_hi = df.loc[0:,'out_unique_meals_purch'][df['unique_meals_purch'] > unique_meals_purch_hi]\n",
    "\n",
    "df['out_unique_meals_purch'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# contacts_w_customer_service_hi_lo\n",
    "df['out_contacts_w_customer_service'] = 0\n",
    "condition_hi = df.loc[0:,'out_contacts_w_customer_service'][df['contacts_w_customer_service'] > contacts_w_customer_service_hi]\n",
    "condition_lo = df.loc[0:,'out_contacts_w_customer_service'][df['contacts_w_customer_service'] < contacts_w_customer_service_lo]\n",
    "\n",
    "df['out_contacts_w_customer_service'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "df['out_contacts_w_customer_service'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# product_categories_viewed_hi_lo\n",
    "df['out_product_categories_viewed'] = 0\n",
    "condition_hi = df.loc[0:,'out_product_categories_viewed'][df['product_categories_viewed'] > product_categories_viewed_hi]\n",
    "condition_lo = df.loc[0:,'out_product_categories_viewed'][df['product_categories_viewed'] < product_categories_viewed_lo]\n",
    "\n",
    "df['out_product_categories_viewed'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "df['out_product_categories_viewed'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# avg_time_per_site_visit_hi_lo\n",
    "df['out_avg_time_per_site_visit'] = 0\n",
    "condition_hi = df.loc[0:,'out_avg_time_per_site_visit'][df['avg_time_per_site_visit'] > avg_time_per_site_visit_hi]\n",
    "condition_lo = df.loc[0:,'out_avg_time_per_site_visit'][df['avg_time_per_site_visit'] < avg_time_per_site_visit_lo]\n",
    "\n",
    "df['out_avg_time_per_site_visit'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "df['out_avg_time_per_site_visit'].replace(to_replace = condition_lo,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# cancellations_before_noon_hi\n",
    "df['out_cancellations_before_noon'] = 0\n",
    "condition_hi = df.loc[0:,'out_cancellations_before_noon'][df['cancellations_before_noon'] > cancellations_before_noon_hi]\n",
    "\n",
    "df['out_cancellations_before_noon'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# cancellations_after_noon_hi\n",
    "df['out_cancellations_after_noon'] = 0\n",
    "condition_hi = df.loc[0:,'out_cancellations_after_noon'][df['cancellations_after_noon'] > cancellations_after_noon_hi]\n",
    "\n",
    "df['out_cancellations_after_noon'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# mobile_logins_lo\n",
    "df['out_mobile_logins'] = 0\n",
    "condition_lo = df.loc[0:,'out_mobile_logins'][df['mobile_logins'] < mobile_logins_lo]\n",
    "\n",
    "df['out_mobile_logins'].replace(to_replace = condition_lo,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# pc_logins_hi_lo\n",
    "df['out_pc_logins'] = 0\n",
    "condition_hi = df.loc[0:,'out_pc_logins'][df['pc_logins'] > pc_logins_hi]\n",
    "condition_lo = df.loc[0:,'out_pc_logins'][df['pc_logins'] < pc_logins_lo]\n",
    "\n",
    "df['out_pc_logins'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "df['out_pc_logins'].replace(to_replace = condition_lo,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# weekly_plan_hi\n",
    "df['out_weekly_plan'] = 0\n",
    "condition_hi = df.loc[0:,'out_weekly_plan'][df['weekly_plan'] > weekly_plan_hi]\n",
    "\n",
    "df['out_weekly_plan'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# early_deliveries_hi\n",
    "df['out_early_deliveries'] = 0\n",
    "condition_hi = df.loc[0:,'out_early_deliveries'][df['early_deliveries'] > early_deliveries_hi]\n",
    "\n",
    "df['out_early_deliveries'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# late_deliveries_hi\n",
    "df['out_late_deliveries'] = 0\n",
    "condition_hi = df.loc[0:,'out_late_deliveries'][df['late_deliveries'] > late_deliveries_hi]\n",
    "\n",
    "df['out_late_deliveries'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# avg_prep_vid_time_hi\n",
    "df['out_avg_prep_vid_time'] = 0\n",
    "condition_hi = df.loc[0:,'out_avg_prep_vid_time'][df['avg_prep_vid_time'] > avg_prep_vid_time_hi]\n",
    "\n",
    "df['out_avg_prep_vid_time'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# largest_order_size_hi_lo\n",
    "df['out_largest_order_size'] = 0\n",
    "condition_hi = df.loc[0:,'out_largest_order_size'][df['largest_order_size'] > largest_order_size_hi]\n",
    "condition_lo = df.loc[0:,'out_largest_order_size'][df['largest_order_size'] < largest_order_size_lo]\n",
    "\n",
    "df['out_largest_order_size'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "df['out_largest_order_size'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# master_classes_attended_hi\n",
    "df['out_master_classes_attended'] = 0\n",
    "condition_hi = df.loc[0:,'out_master_classes_attended'][df['master_classes_attended'] > master_classes_attended_hi]\n",
    "\n",
    "df['out_master_classes_attended'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# median_meal_rating_hi\n",
    "df['out_hi_median_meal_rating'] = 0\n",
    "condition_hi = df.loc[0:,'out_hi_median_meal_rating'][df['median_meal_rating'] > median_meal_rating_hi]\n",
    "\n",
    "df['out_hi_median_meal_rating'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "# median_meal_rating_lo\n",
    "df['out_lo_median_meal_rating'] = 0\n",
    "condition_lo = df.loc[0:,'out_lo_median_meal_rating'][df['median_meal_rating'] < median_meal_rating_lo]\n",
    "\n",
    "df['out_lo_median_meal_rating'].replace(to_replace = condition_lo,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# avg_clicks_per_visit_lo_hi\n",
    "df['out_avg_clicks_per_visit'] = 0\n",
    "condition_hi = df.loc[0:,'out_avg_clicks_per_visit'][df['avg_clicks_per_visit'] > avg_clicks_per_visit_hi]\n",
    "condition_lo = df.loc[0:,'out_avg_clicks_per_visit'][df['avg_clicks_per_visit'] < avg_clicks_per_visit_lo]\n",
    "\n",
    "df['out_avg_clicks_per_visit'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "df['out_avg_clicks_per_visit'].replace(to_replace = condition_lo,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# total_photos_viewed_hi\n",
    "df['out_total_photos_viewed'] = 0\n",
    "condition_hi = df.loc[0:,'out_total_photos_viewed'][df['total_photos_viewed'] > total_photos_viewed_hi]\n",
    "\n",
    "df['out_total_photos_viewed'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# revenue_hi\n",
    "df['out_revenue'] = 0\n",
    "condition_hi = df.loc[0:,'out_revenue'][df['revenue'] > revenue_hi]\n",
    "\n",
    "df['out_revenue'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# lo_revenue_lo\n",
    "df['out_lo_revenue'] = 0\n",
    "condition_lo = df.loc[0:,'out_lo_revenue'][df['revenue'] < revenue_lo]\n",
    "\n",
    "df['out_lo_revenue'].replace(to_replace = condition_lo,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "# avg_spend_hi\n",
    "df['out_avg_spend'] = 0\n",
    "condition_hi = df.loc[0:,'out_avg_spend'][df['avg_spend'] > avg_spend_hi]\n",
    "\n",
    "df['out_avg_spend'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "#perc_complaints_hi\n",
    "df['out_perc_complaints'] = 0\n",
    "condition_hi = df.loc[0:,'out_perc_complaints'][df['perc_complaints'] > perc_complaints_hi]\n",
    "\n",
    "df['out_perc_complaints'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "#new_meal_tendency_hi\n",
    "df['out_new_meal_tendency'] = 0\n",
    "condition_hi = df.loc[0:,'out_new_meal_tendency'][df['new_meal_tendency'] > new_meal_tendency_hi]\n",
    "\n",
    "df['out_new_meal_tendency'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "#perc_meal_plan_hi\n",
    "df['out_perc_meal_plan'] = 0\n",
    "condition_hi = df.loc[0:,'out_perc_meal_plan'][df['perc_meal_plan'] > perc_meal_plan_hi]\n",
    "\n",
    "df['out_perc_meal_plan'].replace(to_replace = condition_hi,\n",
    "                                value      = 1,\n",
    "                                inplace    = True)\n",
    "\n",
    "\n",
    "# declaring explanatory variables\n",
    "df_data = df.drop(['cross_sell_success',\n",
    "                   'name',\n",
    "                   'email',\n",
    "                   'first_name',\n",
    "                   'family_name',\n",
    "                   'email_domain',\n",
    "                   'domain_group',\n",
    "                   'junk',\n",
    "                   'same_names'], \n",
    "                  axis = 1)\n",
    "\n",
    "# declaring response variable\n",
    "df_target = df.loc[ : , 'cross_sell_success']\n",
    "\n",
    "\n",
    "candidate_dict = {\n",
    "# lean set for Random forest\n",
    " 'RF_lean'      : ['professional', 'name_twice',\n",
    "                   'dif_names','followed_recommendations_pct'],\n",
    "}\n",
    "\n",
    "# preparing an empty list for scoring of the models\n",
    "model_performance = [['Model', 'Training Accuracy',\n",
    "                      'Testing Accuracy', 'AUC Value']]\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Train/Test Split\n",
    "################################################################################\n",
    "\n",
    "# use this space to set up testing and validation sets using train/test split\n",
    "\n",
    "# Note: Be sure to set test_size = 0.25\n",
    "\n",
    "# defining variable set\n",
    "df_data   =  df.loc[ : , candidate_dict['RF_lean']]\n",
    "df_target =  df.loc[ : , 'cross_sell_success']\n",
    "\n",
    "\n",
    "# train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            df_data,\n",
    "            df_target,\n",
    "            random_state = 222,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = df_target)\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Final Model (instantiate, fit, and predict)\n",
    "################################################################################\n",
    "\n",
    "# use this space to instantiate, fit, and predict on your final model\n",
    "\n",
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = 8,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = True,\n",
    "                                    random_state     = 222)\n",
    "\n",
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# Final Model Score (score)\n",
    "################################################################################\n",
    "\n",
    "# use this space to score your final model on the testing set\n",
    "# MAKE SURE TO SAVE YOUR TEST SCORE AS test_score\n",
    "# Example: test_score = final_model.score(X_test, y_test)\n",
    "\n",
    "test_score = rf_default_fit.score(X_test, y_test).round(4)\n",
    "auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4)\n",
    "                                          \n",
    "\n",
    "\"\"\"\n",
    "\n",
    " \n",
    "\n",
    "# calculating execution time\n",
    "elapsed_time = timeit.timeit(code_to_test, number=3)/3\n",
    "print(elapsed_time)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
